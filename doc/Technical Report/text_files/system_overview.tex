The system counts the people entering and leaving a room, presents a classification of the severity of potential queues to enter the room, and sends this information to a web server over a REST api. To be able to do this, a Microsoft Kinect is placed over each entrance to the room, and is connected to the computation device that runs the system software for that room. A debug/configuration GUI can be used to calibrate and configure the software. This produces configuration files that are used by the system. Further tuning and configuration can be done by editing the configuration files. 

\begin{figure}[htb]
	\centering
	\includegraphics[width=\linewidth]{images/system_overview.pdf}
	\caption[Overview of the entire system]{\textit{System overview.}}
	\label{fig:system_overview}  %Skapar referens till figuren
\end{figure}

\subsection{Platform and hardware requirements}
The system runs and has been tested on Windows, Mac OS X, and Linux. It has  run at real time frame rates on a Linux virtual machine with as low as ----- insert the smallest processing power tested on VM -----. It has not been tested on any embedded devices but should work given that the device has sufficient processing power. Care must be taken when considering embedded devices so that the USB module can handle the data volumes needed to stream both RGB and depth images from the Kinect device at 30 fps. 

\subsection{Configuration}
The whole system can be configured by editing the plain text YAML configuration files. Among other things, it is possible to set what image processing algorithms should be run, in what order to run them and the value of most parameters. Many components in the Debug GUI, camera settings and important file paths are also set in the configuration files. 

\subsection{Modular software design}
The software has a modular and easily extendible design. The main components of the system are divided into different modules that can easily be swapped. 

\subsubsection{Network module}
The network module manages all system input/output, i.e. sampling the sensors and posting output data on the web server specified by the configuration file. Currently, support exists for all OpenCV-compatible cameras as well as the Microsoft Kinect depth sensor. The module is designed to be as modular as possible, allowing for a relatively easy integration of new sensor types into the system. The network module also supports running several sensors in parallel. 

\subsection{Algorithm Interface}
The algorithm interface simplifies the addition of new image processing or tracking modules to the system. Together with the config file, this allows a very flexible software system that could be used for virtually any computer vision problem. (Add more here)

\subsection{Debug and Config GUI}
Debug GUI features (Image and stuff)
Configuration GUI management (more image and such)
